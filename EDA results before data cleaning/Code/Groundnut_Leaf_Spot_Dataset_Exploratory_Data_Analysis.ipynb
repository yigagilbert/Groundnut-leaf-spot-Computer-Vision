{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1epau1m6yAK5PKl2HkLNyKo3WRS-6Bhqy?usp=sharing)"
      ],
      "metadata": {
        "id": "27YRBqP7PNuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install numpy matplotlib seaborn opencv-python pillow pandas tqdm scikit-image scikit-learn"
      ],
      "metadata": {
        "id": "b1EHNqmXAGay"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before Data cleaning and annotation"
      ],
      "metadata": {
        "id": "lNTVxqT0-1tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from sklearn.decomposition import PCA\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "PWyBxvaTBG6q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Iv5fmN-U-y4l"
      },
      "outputs": [],
      "source": [
        "class GroundnutLeafspotEDA:\n",
        "    def __init__(self, dataset_path):\n",
        "        \"\"\"\n",
        "        Initialize with the path to the Groundnut leaf spot dataset.\n",
        "\n",
        "        Args:\n",
        "            dataset_path (str): Path to the parent folder containing the 6 scale folders\n",
        "        \"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.classes = [\"Leafspot Scale 1\", \"Leafspot Scale 2\", \"Leafspot Scale 3\",\n",
        "                        \"Leafspot Scale 4\", \"Leafspot Scale 5\", \"Leafspot Scale 6\"]\n",
        "        self.results = {}\n",
        "\n",
        "    def analyze_dataset_structure(self):\n",
        "        \"\"\"Analyze the structure of the dataset and count images per class\"\"\"\n",
        "        print(\"Analyzing dataset structure...\")\n",
        "\n",
        "        class_counts = {}\n",
        "        total_images = 0\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                print(f\"Warning: Path {class_path} does not exist.\")\n",
        "                class_counts[class_name] = 0\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "            class_counts[class_name] = len(image_files)\n",
        "            total_images += len(image_files)\n",
        "\n",
        "        self.results['class_counts'] = class_counts\n",
        "        self.results['total_images'] = total_images\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"Total images: {total_images}\")\n",
        "        for class_name, count in class_counts.items():\n",
        "            print(f\"{class_name}: {count} images ({count/total_images*100:.2f}%)\")\n",
        "\n",
        "        # Create distribution plot\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
        "        plt.title(\"Distribution of Images Across Classes\")\n",
        "        plt.xlabel(\"Class\")\n",
        "        plt.ylabel(\"Number of Images\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"class_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        return class_counts\n",
        "\n",
        "    def analyze_image_properties(self, sample_size=100):\n",
        "        \"\"\"\n",
        "        Analyze properties of images: dimensions, aspect ratios, file sizes, formats\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class for analysis\n",
        "        \"\"\"\n",
        "        print(\"Analyzing image properties...\")\n",
        "\n",
        "        dimensions = []\n",
        "        aspect_ratios = []\n",
        "        file_sizes = []\n",
        "        file_formats = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                image_files = random.sample(image_files, sample_size)\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                # Get file size\n",
        "                file_size = os.path.getsize(img_path) / 1024  # size in KB\n",
        "                file_sizes.append(file_size)\n",
        "\n",
        "                # Get file format\n",
        "                file_format = os.path.splitext(img_file)[1].lower()\n",
        "                file_formats.append(file_format)\n",
        "\n",
        "                # Open image to get dimensions\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        width, height = img.size\n",
        "                        dimensions.append((width, height))\n",
        "                        aspect_ratio = width / height\n",
        "                        aspect_ratios.append(aspect_ratio)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['dimensions'] = dimensions\n",
        "        self.results['aspect_ratios'] = aspect_ratios\n",
        "        self.results['file_sizes'] = file_sizes\n",
        "        self.results['file_formats'] = file_formats\n",
        "\n",
        "        # Create visualizations\n",
        "\n",
        "        # Image dimensions scatter plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        width, height = zip(*dimensions)\n",
        "        plt.scatter(width, height, alpha=0.5)\n",
        "        plt.title(\"Image Dimensions\")\n",
        "        plt.xlabel(\"Width (pixels)\")\n",
        "        plt.ylabel(\"Height (pixels)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"image_dimensions.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Aspect ratio histogram\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(aspect_ratios, bins=20)\n",
        "        plt.title(\"Distribution of Aspect Ratios\")\n",
        "        plt.xlabel(\"Aspect Ratio (width/height)\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"aspect_ratios.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # File size histogram\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(file_sizes, bins=20)\n",
        "        plt.title(\"Distribution of File Sizes\")\n",
        "        plt.xlabel(\"File Size (KB)\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"file_sizes.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # File formats pie chart\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        format_counts = Counter(file_formats)\n",
        "        plt.pie(format_counts.values(), labels=format_counts.keys(), autopct='%1.1f%%')\n",
        "        plt.title(\"Distribution of File Formats\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"file_formats.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def analyze_image_quality(self, sample_size=50):\n",
        "        \"\"\"\n",
        "        Analyze image quality: brightness, contrast, blur, noise\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class\n",
        "        \"\"\"\n",
        "        print(\"Analyzing image quality...\")\n",
        "\n",
        "        brightness_values = []\n",
        "        contrast_values = []\n",
        "        blur_scores = []\n",
        "\n",
        "        class_brightness = {c: [] for c in self.classes}\n",
        "        class_contrast = {c: [] for c in self.classes}\n",
        "        class_blur = {c: [] for c in self.classes}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                image_files = random.sample(image_files, sample_size)\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                try:\n",
        "                    # Read image with OpenCV\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Could not read {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    # Convert to grayscale for some metrics\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Calculate brightness (mean pixel value)\n",
        "                    brightness = np.mean(gray)\n",
        "                    brightness_values.append(brightness)\n",
        "                    class_brightness[class_name].append(brightness)\n",
        "\n",
        "                    # Calculate contrast (standard deviation of pixel values)\n",
        "                    contrast = np.std(gray)\n",
        "                    contrast_values.append(contrast)\n",
        "                    class_contrast[class_name].append(contrast)\n",
        "\n",
        "                    # Calculate blur score using Laplacian variance\n",
        "                    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "                    blur_score = np.var(laplacian)\n",
        "                    blur_scores.append(blur_score)\n",
        "                    class_blur[class_name].append(blur_score)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['brightness_values'] = brightness_values\n",
        "        self.results['contrast_values'] = contrast_values\n",
        "        self.results['blur_scores'] = blur_scores\n",
        "        self.results['class_brightness'] = class_brightness\n",
        "        self.results['class_contrast'] = class_contrast\n",
        "        self.results['class_blur'] = class_blur\n",
        "\n",
        "        # Create visualizations\n",
        "\n",
        "        # Brightness distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(brightness_values, bins=20)\n",
        "        plt.title(\"Distribution of Image Brightness\")\n",
        "        plt.xlabel(\"Brightness (mean pixel value)\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"brightness_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Contrast distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(contrast_values, bins=20)\n",
        "        plt.title(\"Distribution of Image Contrast\")\n",
        "        plt.xlabel(\"Contrast (std of pixel values)\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"contrast_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Blur score distribution\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(blur_scores, bins=20)\n",
        "        plt.title(\"Distribution of Image Blur Scores\")\n",
        "        plt.xlabel(\"Blur Score (Laplacian variance)\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"blur_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Boxplot of brightness by class\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        data_to_plot = [values for class_name, values in class_brightness.items() if values]\n",
        "        plt.boxplot(data_to_plot, labels=[c for c in class_brightness.keys() if class_brightness[c]])\n",
        "        plt.title(\"Brightness Distribution by Class\")\n",
        "        plt.xlabel(\"Class\")\n",
        "        plt.ylabel(\"Brightness\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"brightness_by_class.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Boxplot of contrast by class\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        data_to_plot = [values for class_name, values in class_contrast.items() if values]\n",
        "        plt.boxplot(data_to_plot, labels=[c for c in class_contrast.keys() if class_contrast[c]])\n",
        "        plt.title(\"Contrast Distribution by Class\")\n",
        "        plt.xlabel(\"Class\")\n",
        "        plt.ylabel(\"Contrast\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"contrast_by_class.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def analyze_color_distribution(self, sample_size=50):\n",
        "        \"\"\"\n",
        "        Analyze color distributions across images and classes\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class\n",
        "        \"\"\"\n",
        "        print(\"Analyzing color distributions...\")\n",
        "\n",
        "        # Collect average RGB values per image and class\n",
        "        avg_colors = {c: {'r': [], 'g': [], 'b': []} for c in self.classes}\n",
        "        all_colors = {'r': [], 'g': [], 'b': []}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                image_files = random.sample(image_files, sample_size)\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                try:\n",
        "                    # Read image with OpenCV (BGR format)\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "\n",
        "                    # Convert BGR to RGB\n",
        "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                    # Calculate average RGB\n",
        "                    avg_r = np.mean(img_rgb[:, :, 0])\n",
        "                    avg_g = np.mean(img_rgb[:, :, 1])\n",
        "                    avg_b = np.mean(img_rgb[:, :, 2])\n",
        "\n",
        "                    # Store by class\n",
        "                    avg_colors[class_name]['r'].append(avg_r)\n",
        "                    avg_colors[class_name]['g'].append(avg_g)\n",
        "                    avg_colors[class_name]['b'].append(avg_b)\n",
        "\n",
        "                    # Store all colors\n",
        "                    all_colors['r'].append(avg_r)\n",
        "                    all_colors['g'].append(avg_g)\n",
        "                    all_colors['b'].append(avg_b)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['avg_colors'] = avg_colors\n",
        "        self.results['all_colors'] = all_colors\n",
        "\n",
        "        # Create visualizations\n",
        "\n",
        "        # RGB distribution across all images\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.hist(all_colors['r'], bins=20, color='red', alpha=0.7)\n",
        "        plt.title(\"Red Channel Distribution\")\n",
        "        plt.xlabel(\"Average Red Value\")\n",
        "        plt.ylabel(\"Count\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.hist(all_colors['g'], bins=20, color='green', alpha=0.7)\n",
        "        plt.title(\"Green Channel Distribution\")\n",
        "        plt.xlabel(\"Average Green Value\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.hist(all_colors['b'], bins=20, color='blue', alpha=0.7)\n",
        "        plt.title(\"Blue Channel Distribution\")\n",
        "        plt.xlabel(\"Average Blue Value\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"rgb_distribution.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # 3D scatter plot of RGB values by class\n",
        "        fig = plt.figure(figsize=(10, 8))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        colors = ['r', 'g', 'b', 'c', 'm', 'y']\n",
        "\n",
        "        for i, class_name in enumerate(self.classes):\n",
        "            if not avg_colors[class_name]['r']:  # Skip if empty\n",
        "                continue\n",
        "\n",
        "            ax.scatter(\n",
        "                avg_colors[class_name]['r'],\n",
        "                avg_colors[class_name]['g'],\n",
        "                avg_colors[class_name]['b'],\n",
        "                c=colors[i % len(colors)],\n",
        "                label=class_name,\n",
        "                alpha=0.7\n",
        "            )\n",
        "\n",
        "        ax.set_xlabel('Red')\n",
        "        ax.set_ylabel('Green')\n",
        "        ax.set_zlabel('Blue')\n",
        "        ax.set_title('RGB Color Distribution by Class')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"rgb_by_class_3d.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def detect_potential_issues(self, sample_size=30):\n",
        "        \"\"\"\n",
        "        Detect potential issues in the dataset that need cleaning or special attention\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class\n",
        "        \"\"\"\n",
        "        print(\"Detecting potential issues...\")\n",
        "\n",
        "        issues = {\n",
        "            'duplicates': [],\n",
        "            'corrupted': [],\n",
        "            'very_low_brightness': [],\n",
        "            'very_high_brightness': [],\n",
        "            'very_blurry': [],\n",
        "            'unusual_aspect_ratio': [],\n",
        "            'outlier_size': []\n",
        "        }\n",
        "\n",
        "        # Set thresholds for issue detection\n",
        "        brightness_low_threshold = 40\n",
        "        brightness_high_threshold = 220\n",
        "        blur_threshold = 50  # Lower values indicate more blur\n",
        "        aspect_ratio_thresholds = (0.5, 2.0)  # (min, max)\n",
        "\n",
        "        # Sample images for processing\n",
        "        all_image_files = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [os.path.join(class_path, f) for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                sampled_files = random.sample(image_files, sample_size)\n",
        "            else:\n",
        "                sampled_files = image_files\n",
        "\n",
        "            all_image_files.extend(sampled_files)\n",
        "\n",
        "        # Process each image\n",
        "        for img_path in tqdm(all_image_files, desc=\"Checking images\"):\n",
        "            try:\n",
        "                # Try to open the image\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    issues['corrupted'].append(img_path)\n",
        "                    continue\n",
        "\n",
        "                # Check brightness\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                brightness = np.mean(gray)\n",
        "\n",
        "                if brightness < brightness_low_threshold:\n",
        "                    issues['very_low_brightness'].append((img_path, brightness))\n",
        "                elif brightness > brightness_high_threshold:\n",
        "                    issues['very_high_brightness'].append((img_path, brightness))\n",
        "\n",
        "                # Check blur\n",
        "                laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "                blur_score = np.var(laplacian)\n",
        "\n",
        "                if blur_score < blur_threshold:\n",
        "                    issues['very_blurry'].append((img_path, blur_score))\n",
        "\n",
        "                # Check aspect ratio\n",
        "                height, width = img.shape[:2]\n",
        "                aspect_ratio = width / height\n",
        "\n",
        "                if aspect_ratio < aspect_ratio_thresholds[0] or aspect_ratio > aspect_ratio_thresholds[1]:\n",
        "                    issues['unusual_aspect_ratio'].append((img_path, aspect_ratio))\n",
        "\n",
        "                # Check file size\n",
        "                file_size = os.path.getsize(img_path) / 1024  # KB\n",
        "                if file_size < 10 or file_size > 1000:  # Example thresholds\n",
        "                    issues['outlier_size'].append((img_path, file_size))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {img_path}: {e}\")\n",
        "                issues['corrupted'].append(img_path)\n",
        "\n",
        "        # Store results\n",
        "        self.results['issues'] = issues\n",
        "\n",
        "        # Print summary of issues\n",
        "        print(\"\\nPotential issues detected:\")\n",
        "        for issue_type, issue_list in issues.items():\n",
        "            print(f\"  {issue_type}: {len(issue_list)} images\")\n",
        "\n",
        "        return issues\n",
        "\n",
        "    def sample_images_by_class(self, samples_per_class=5, figsize=(15, 10)):\n",
        "        \"\"\"\n",
        "        Display random sample images from each class\n",
        "\n",
        "        Args:\n",
        "            samples_per_class (int): Number of sample images to display per class\n",
        "            figsize (tuple): Figure size for the display\n",
        "        \"\"\"\n",
        "        print(\"Sampling images from each class...\")\n",
        "\n",
        "        # Determine grid dimensions\n",
        "        n_classes = len(self.classes)\n",
        "        n_samples = samples_per_class\n",
        "\n",
        "        fig, axes = plt.subplots(n_classes, n_samples, figsize=figsize)\n",
        "\n",
        "        # Make sure axes is 2D even if there's only one class\n",
        "        if n_classes == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "\n",
        "        for i, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Skip if no images in this class\n",
        "            if not image_files:\n",
        "                continue\n",
        "\n",
        "            # Select random samples\n",
        "            if len(image_files) > n_samples:\n",
        "                selected_files = random.sample(image_files, n_samples)\n",
        "            else:\n",
        "                selected_files = image_files\n",
        "\n",
        "            # Fill remaining slots with blank images if needed\n",
        "            selected_files.extend([''] * (n_samples - len(selected_files)))\n",
        "\n",
        "            # Display each sample\n",
        "            for j, img_file in enumerate(selected_files[:n_samples]):\n",
        "                if not img_file:\n",
        "                    axes[i, j].axis('off')\n",
        "                    continue\n",
        "\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    axes[i, j].imshow(img)\n",
        "                    axes[i, j].set_title(f\"{class_name}\\n{img_file[:10]}...\")\n",
        "                    axes[i, j].axis('off')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error displaying {img_path}: {e}\")\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"sample_images.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def analyze_texture_features(self, sample_size=30):\n",
        "        \"\"\"\n",
        "        Analyze texture features using GLCM and visualize differences between classes\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class\n",
        "        \"\"\"\n",
        "        print(\"Analyzing texture features...\")\n",
        "\n",
        "        # Features to extract\n",
        "        properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
        "\n",
        "        # Dictionary to store features by class\n",
        "        texture_features = {c: {prop: [] for prop in properties} for c in self.classes}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                image_files = random.sample(image_files, sample_size)\n",
        "\n",
        "            for img_file in tqdm(image_files, desc=f\"Processing {class_name}\"):\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                try:\n",
        "                    # Read image and convert to grayscale\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Resize to reduce computation time if needed\n",
        "                    resized = cv2.resize(gray, (128, 128))\n",
        "\n",
        "                    # Calculate GLCM\n",
        "                    distances = [1]\n",
        "                    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "                    glcm = graycomatrix(resized, distances=distances, angles=angles,\n",
        "                                      levels=256, symmetric=True, normed=True)\n",
        "\n",
        "                    # Calculate properties\n",
        "                    for prop in properties:\n",
        "                        glcm_prop = graycoprops(glcm, prop).mean()\n",
        "                        texture_features[class_name][prop].append(glcm_prop)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['texture_features'] = texture_features\n",
        "\n",
        "        # Create visualizations for each property\n",
        "        for prop in properties:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "\n",
        "            data_to_plot = []\n",
        "            labels = []\n",
        "\n",
        "            for class_name in self.classes:\n",
        "                if texture_features[class_name][prop]:\n",
        "                    data_to_plot.append(texture_features[class_name][prop])\n",
        "                    labels.append(class_name)\n",
        "\n",
        "            if data_to_plot:\n",
        "                plt.boxplot(data_to_plot, labels=labels)\n",
        "                plt.title(f\"GLCM {prop.capitalize()} by Class\")\n",
        "                plt.xlabel(\"Class\")\n",
        "                plt.ylabel(prop.capitalize())\n",
        "                plt.xticks(rotation=45)\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(f\"texture_{prop}.png\")\n",
        "\n",
        "            plt.close()\n",
        "\n",
        "        # Create PCA visualization for texture features\n",
        "        self.visualize_texture_pca(texture_features, properties)\n",
        "\n",
        "    def visualize_texture_pca(self, texture_features, properties):\n",
        "        \"\"\"\n",
        "        Create PCA visualization for texture features to see class separability\n",
        "\n",
        "        Args:\n",
        "            texture_features (dict): Dictionary of texture features by class\n",
        "            properties (list): List of feature properties used\n",
        "        \"\"\"\n",
        "        # Prepare data for PCA\n",
        "        X = []\n",
        "        y = []\n",
        "        class_names = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            if not any(texture_features[class_name].values()):\n",
        "                continue\n",
        "\n",
        "            class_names.append(class_name)\n",
        "            n_samples = len(texture_features[class_name][properties[0]])\n",
        "\n",
        "            for i in range(n_samples):\n",
        "                features = [texture_features[class_name][prop][i] for prop in properties]\n",
        "                X.append(features)\n",
        "                y.append(class_names.index(class_name))\n",
        "\n",
        "        if not X:\n",
        "            return\n",
        "\n",
        "        X = np.array(X)\n",
        "\n",
        "        # Apply PCA\n",
        "        pca = PCA(n_components=2)\n",
        "        X_pca = pca.fit_transform(X)\n",
        "\n",
        "        # Create scatter plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        colors = plt.cm.tab10(np.linspace(0, 1, len(class_names)))\n",
        "\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            idx = np.array(y) == i\n",
        "            plt.scatter(X_pca[idx, 0], X_pca[idx, 1], c=[colors[i]],\n",
        "                      label=class_name, alpha=0.7)\n",
        "\n",
        "        plt.title(\"PCA of Texture Features\")\n",
        "        plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)\")\n",
        "        plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"texture_pca.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def generate_eda_report(self):\n",
        "        \"\"\"Generate a summary report of the EDA findings\"\"\"\n",
        "        report = {\n",
        "            \"dataset_summary\": {\n",
        "                \"total_images\": self.results.get('total_images', 0),\n",
        "                \"class_counts\": self.results.get('class_counts', {})\n",
        "            },\n",
        "            \"image_properties\": {\n",
        "                \"unique_dimensions\": len(set(self.results.get('dimensions', []))),\n",
        "                \"avg_file_size_kb\": np.mean(self.results.get('file_sizes', [0])),\n",
        "                \"file_formats\": Counter(self.results.get('file_formats', []))\n",
        "            },\n",
        "            \"image_quality\": {\n",
        "                \"avg_brightness\": np.mean(self.results.get('brightness_values', [0])),\n",
        "                \"avg_contrast\": np.mean(self.results.get('contrast_values', [0])),\n",
        "                \"avg_blur_score\": np.mean(self.results.get('blur_scores', [0]))\n",
        "            },\n",
        "            \"issues_summary\": {\n",
        "                issue_type: len(issues)\n",
        "                for issue_type, issues in self.results.get('issues', {}).items()\n",
        "            },\n",
        "            \"cleaning_recommendations\": []\n",
        "        }\n",
        "\n",
        "        # Generate cleaning recommendations\n",
        "        if self.results.get('issues'):\n",
        "            issues = self.results['issues']\n",
        "\n",
        "            if len(issues.get('corrupted', [])) > 0:\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    f\"Remove {len(issues['corrupted'])} corrupted images that couldn't be opened.\")\n",
        "\n",
        "            if len(issues.get('very_low_brightness', [])) > 0:\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    f\"Consider adjusting brightness for {len(issues['very_low_brightness'])} very dark images.\")\n",
        "\n",
        "            if len(issues.get('very_high_brightness', [])) > 0:\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    f\"Consider adjusting brightness for {len(issues['very_high_brightness'])} very bright images.\")\n",
        "\n",
        "            if len(issues.get('very_blurry', [])) > 0:\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    f\"Consider removing or enhancing {len(issues['very_blurry'])} blurry images.\")\n",
        "\n",
        "            if len(issues.get('unusual_aspect_ratio', [])) > 0:\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    f\"Standardize dimensions for {len(issues['unusual_aspect_ratio'])} images with unusual aspect ratios.\")\n",
        "\n",
        "        # Class imbalance check\n",
        "        if self.results.get('class_counts'):\n",
        "            counts = list(self.results['class_counts'].values())\n",
        "            if max(counts) > 2 * min(counts):\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    \"Address class imbalance through augmentation of minority classes or sampling strategies.\")\n",
        "\n",
        "        # Standard deviation of brightness across classes\n",
        "        if self.results.get('class_brightness'):\n",
        "            class_means = [np.mean(vals) for vals in self.results['class_brightness'].values() if vals]\n",
        "            if class_means and np.std(class_means) > 20:  # Arbitrary threshold\n",
        "                report['cleaning_recommendations'].append(\n",
        "                    \"Consider normalizing brightness across classes as there is significant variation.\")\n",
        "\n",
        "        # Print report\n",
        "        print(\"\\n========== EDA REPORT ==========\")\n",
        "        print(f\"Dataset contains {report['dataset_summary']['total_images']} images across {len(report['dataset_summary']['class_counts'])} classes\")\n",
        "\n",
        "        print(\"\\nImage Properties:\")\n",
        "        print(f\"  - {report['image_properties']['unique_dimensions']} unique image dimensions\")\n",
        "        print(f\"  - Average file size: {report['image_properties']['avg_file_size_kb']:.2f} KB\")\n",
        "        print(f\"  - File formats: {dict(report['image_properties']['file_formats'])}\")\n",
        "\n",
        "        print(\"\\nImage Quality:\")\n",
        "        print(f\"  - Average brightness: {report['image_quality']['avg_brightness']:.2f}\")\n",
        "        print(f\"  - Average contrast: {report['image_quality']['avg_contrast']:.2f}\")\n",
        "        print(f\"  - Average blur score: {report['image_quality']['avg_blur_score']:.2f}\")\n",
        "\n",
        "        print(\"\\nIssues Detected:\")\n",
        "        for issue_type, count in report['issues_summary'].items():\n",
        "            print(f\"  - {issue_type}: {count}\")\n",
        "\n",
        "        print(\"\\nCleaning Recommendations:\")\n",
        "        for i, rec in enumerate(report['cleaning_recommendations'], 1):\n",
        "            print(f\"  {i}. {rec}\")\n",
        "\n",
        "        return report\n",
        "\n",
        "    def analyze_leafspot_specific_features(self, sample_size=30):\n",
        "        \"\"\"\n",
        "        Analyze features specific to leaf spot disease severity scales\n",
        "\n",
        "        Args:\n",
        "            sample_size (int): Number of images to sample from each class\n",
        "        \"\"\"\n",
        "        print(\"Analyzing leaf spot specific features...\")\n",
        "\n",
        "        # Store leaf spot related metrics by class\n",
        "        spot_metrics = {c: {\n",
        "            'spot_count': [],\n",
        "            'spot_area_percent': [],\n",
        "            'leaf_area_percent': []\n",
        "        } for c in self.classes}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.dataset_path, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "            # Sample images if there are too many\n",
        "            if len(image_files) > sample_size:\n",
        "                image_files = random.sample(image_files, sample_size)\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "\n",
        "                try:\n",
        "                    # Read image\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "\n",
        "                    # Convert to HSV to better isolate leaf and spots\n",
        "                    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "                    # Detect green areas (likely leaf areas)\n",
        "                    # Adjust these ranges based on your specific dataset\n",
        "                    lower_green = np.array([25, 40, 40])\n",
        "                    upper_green = np.array([85, 255, 255])\n",
        "                    leaf_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "                    # Detect potential leaf spots (darker regions in the green areas)\n",
        "                    # Here we use a simple threshold, but more sophisticated methods can be used\n",
        "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                    _, spot_mask = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "                    # Apply the leaf mask to only look for spots on the leaf\n",
        "                    spot_on_leaf = cv2.bitwise_and(spot_mask, spot_mask, mask=leaf_mask)\n",
        "\n",
        "                    # Count spots (connected components)\n",
        "                    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(spot_on_leaf, connectivity=8)\n",
        "                    # Subtract 1 to exclude the background\n",
        "                    spot_count = num_labels - 1 if num_labels > 0 else 0\n",
        "\n",
        "                    # Calculate area percentages\n",
        "                    img_area = img.shape[0] * img.shape[1]\n",
        "                    leaf_area = cv2.countNonZero(leaf_mask)\n",
        "                    spot_area = cv2.countNonZero(spot_on_leaf)\n",
        "\n",
        "                    leaf_area_percent = (leaf_area / img_area) * 100\n",
        "                    spot_area_percent = (spot_area / leaf_area) * 100 if leaf_area > 0 else 0\n",
        "\n",
        "                    # Store metrics\n",
        "                    spot_metrics[class_name]['spot_count'].append(spot_count)\n",
        "                    spot_metrics[class_name]['spot_area_percent'].append(spot_area_percent)\n",
        "                    spot_metrics[class_name]['leaf_area_percent'].append(leaf_area_percent)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['spot_metrics'] = spot_metrics\n",
        "\n",
        "        # Create visualizations\n",
        "\n",
        "        # Box plot of spot count by class\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        data_to_plot = []\n",
        "        labels = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            if spot_metrics[class_name]['spot_count']:\n",
        "                data_to_plot.append(spot_metrics[class_name]['spot_count'])\n",
        "                labels.append(class_name)\n",
        "\n",
        "        if data_to_plot:\n",
        "            plt.boxplot(data_to_plot, labels=labels)\n",
        "            plt.title(\"Leaf Spot Count by Class\")\n",
        "            plt.xlabel(\"Class\")\n",
        "            plt.ylabel(\"Number of Spots\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"spot_count_by_class.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Box plot of spot area percentage by class\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        data_to_plot = []\n",
        "        labels = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            if spot_metrics[class_name]['spot_area_percent']:\n",
        "                data_to_plot.append(spot_metrics[class_name]['spot_area_percent'])\n",
        "                labels.append(class_name)\n",
        "\n",
        "        if data_to_plot:\n",
        "            plt.boxplot(data_to_plot, labels=labels)\n",
        "            plt.title(\"Leaf Spot Area Percentage by Class\")\n",
        "            plt.xlabel(\"Class\")\n",
        "            plt.ylabel(\"Spot Area % of Leaf\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"spot_area_by_class.png\")\n",
        "        plt.close()\n",
        "\n",
        "        return spot_metrics\n",
        "\n",
        "    def run_full_eda(self, output_dir=\"./eda_results\"):\n",
        "        \"\"\"\n",
        "        Run full EDA pipeline and save results\n",
        "\n",
        "        Args:\n",
        "            output_dir (str): Directory to save EDA results\n",
        "        \"\"\"\n",
        "        # Create output directory if it doesn't exist\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Change working directory to output dir for saving results\n",
        "        original_dir = os.getcwd()\n",
        "        os.chdir(output_dir)\n",
        "\n",
        "        print(f\"Running full EDA on Groundnut Leaf Spot dataset at {self.dataset_path}\")\n",
        "        print(f\"Results will be saved to {output_dir}\")\n",
        "\n",
        "        # Run all analysis methods\n",
        "        self.analyze_dataset_structure()\n",
        "        self.analyze_image_properties()\n",
        "        self.analyze_image_quality()\n",
        "        self.analyze_color_distribution()\n",
        "        self.sample_images_by_class()\n",
        "        self.analyze_texture_features()\n",
        "        self.analyze_leafspot_specific_features()\n",
        "        self.detect_potential_issues()\n",
        "\n",
        "        # Generate summary report\n",
        "        report = self.generate_eda_report()\n",
        "\n",
        "        # Save report as JSON\n",
        "        with open(\"eda_report.json\", \"w\") as f:\n",
        "            json.dump(report, f, indent=4)\n",
        "\n",
        "        # Save report as markdown\n",
        "        with open(\"eda_report.md\", \"w\") as f:\n",
        "            f.write(\"# Groundnut Leaf Spot Dataset EDA Report\\n\\n\")\n",
        "\n",
        "            f.write(\"## Dataset Summary\\n\")\n",
        "            f.write(f\"- Total images: {report['dataset_summary']['total_images']}\\n\")\n",
        "            f.write(\"- Class distribution:\\n\")\n",
        "            for cls, count in report['dataset_summary']['class_counts'].items():\n",
        "                f.write(f\"  - {cls}: {count} images ({count/report['dataset_summary']['total_images']*100:.2f}%)\\n\")\n",
        "\n",
        "            f.write(\"\\n## Image Properties\\n\")\n",
        "            f.write(f\"- Unique dimensions: {report['image_properties']['unique_dimensions']}\\n\")\n",
        "            f.write(f\"- Average file size: {report['image_properties']['avg_file_size_kb']:.2f} KB\\n\")\n",
        "            f.write(\"- File formats:\\n\")\n",
        "            for fmt, count in report['image_properties']['file_formats'].items():\n",
        "                f.write(f\"  - {fmt}: {count}\\n\")\n",
        "\n",
        "            f.write(\"\\n## Image Quality\\n\")\n",
        "            f.write(f\"- Average brightness: {report['image_quality']['avg_brightness']:.2f}\\n\")\n",
        "            f.write(f\"- Average contrast: {report['image_quality']['avg_contrast']:.2f}\\n\")\n",
        "            f.write(f\"- Average blur score: {report['image_quality']['avg_blur_score']:.2f}\\n\")\n",
        "\n",
        "            f.write(\"\\n## Issues Detected\\n\")\n",
        "            for issue_type, count in report['issues_summary'].items():\n",
        "                f.write(f\"- {issue_type}: {count}\\n\")\n",
        "\n",
        "            f.write(\"\\n## Cleaning Recommendations\\n\")\n",
        "            for i, rec in enumerate(report['cleaning_recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "\n",
        "            f.write(\"\\n## Visualizations\\n\")\n",
        "            f.write(\"The following visualizations were generated during EDA:\\n\\n\")\n",
        "\n",
        "            # List all PNG files\n",
        "            vis_files = [f for f in os.listdir() if f.endswith('.png')]\n",
        "            for vis_file in vis_files:\n",
        "                name = vis_file.replace('_', ' ').replace('.png', '')\n",
        "                f.write(f\"- [{name}]({vis_file})\\n\")\n",
        "\n",
        "        # Return to original directory\n",
        "        os.chdir(original_dir)\n",
        "\n",
        "        print(f\"\\nEDA completed. Results saved to {output_dir}\")\n",
        "\n",
        "        return report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for image annotation suggestions\n",
        "def suggest_annotation_approach(spot_metrics, class_counts):\n",
        "    \"\"\"\n",
        "    Suggest appropriate annotation approaches based on EDA results\n",
        "\n",
        "    Args:\n",
        "        spot_metrics (dict): Metrics related to leaf spots from EDA\n",
        "        class_counts (dict): Number of images per class\n",
        "\n",
        "    Returns:\n",
        "        dict: Annotation recommendations\n",
        "    \"\"\"\n",
        "    # Initialize recommendations\n",
        "    recommendations = {\n",
        "        \"annotation_type\": None,\n",
        "        \"tools\": [],\n",
        "        \"approach\": \"\",\n",
        "        \"special_considerations\": []\n",
        "    }\n",
        "\n",
        "    # Calculate average spot counts across classes\n",
        "    avg_spot_counts = {}\n",
        "    for class_name, metrics in spot_metrics.items():\n",
        "        if metrics['spot_count']:\n",
        "            avg_spot_counts[class_name] = np.mean(metrics['spot_count'])\n",
        "\n",
        "    # Determine annotation type based on average spot counts\n",
        "    max_avg_spots = max(avg_spot_counts.values()) if avg_spot_counts else 0\n",
        "\n",
        "    if max_avg_spots > 20:\n",
        "        # Many spots - semantic segmentation might be best\n",
        "        recommendations[\"annotation_type\"] = \"semantic_segmentation\"\n",
        "        recommendations[\"tools\"] = [\"LabelMe\", \"CVAT\", \"Supervisely\"]\n",
        "        recommendations[\"approach\"] = \"Use pixel-level segmentation to mark all leaf spot areas. This will provide the most detailed information for severe cases.\"\n",
        "        recommendations[\"special_considerations\"].append(\"Focus on accurately marking boundaries between healthy and diseased tissue.\")\n",
        "    elif max_avg_spots > 5:\n",
        "        # Moderate number of spots - could do instance segmentation or object detection\n",
        "        recommendations[\"annotation_type\"] = \"instance_segmentation\"\n",
        "        recommendations[\"tools\"] = [\"VGG Image Annotator (VIA)\", \"CVAT\", \"Roboflow\"]\n",
        "        recommendations[\"approach\"] = \"Mark individual spots as separate instances. This will help differentiate between spot sizes and distributions.\"\n",
        "        recommendations[\"special_considerations\"].append(\"Consider grouping very small spots if they're clustered together.\")\n",
        "    else:\n",
        "        # Few spots - bounding boxes might be sufficient\n",
        "        recommendations[\"annotation_type\"] = \"object_detection\"\n",
        "        recommendations[\"tools\"] = [\"LabelImg\", \"CVAT\", \"Roboflow\"]\n",
        "        recommendations[\"approach\"] = \"Use bounding boxes around individual leaf spots. For early stages with few spots, this is efficient and sufficient.\"\n",
        "        recommendations[\"special_considerations\"].append(\"Make sure to annotate even small or faint spots in early disease stages.\")\n",
        "\n",
        "    # Additional considerations\n",
        "    total_images = sum(class_counts.values())\n",
        "\n",
        "    if total_images > 1000:\n",
        "        recommendations[\"special_considerations\"].append(\"Given the large dataset size, consider active learning approaches to prioritize which images to annotate.\")\n",
        "\n",
        "    # Check for class imbalance\n",
        "    if max(class_counts.values()) > 2 * min(class_counts.values()):\n",
        "        recommendations[\"special_considerations\"].append(\"Address class imbalance by ensuring thorough annotation of minority classes.\")\n",
        "\n",
        "    # Add annotation schema recommendation\n",
        "    recommendations[\"annotation_schema\"] = {\n",
        "        \"classes\": [\"leaf\", \"leaf_spot\"],\n",
        "        \"attributes\": {\n",
        "            \"leaf\": [\"healthy\", \"diseased\"],\n",
        "            \"leaf_spot\": [\"severity_scale\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "Y_AMjJ-LA9wu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    import json\n",
        "\n",
        "\n",
        "    # Run EDA\n",
        "    eda = GroundnutLeafspotEDA(\"/content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Data/wetransfer_leafspot-scores-photos_2024-03-20_1533\")\n",
        "    report = eda.run_full_eda(\"/content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Output_v1\")\n",
        "\n",
        "    # Generate annotation recommendations\n",
        "    if 'spot_metrics' in eda.results and 'class_counts' in eda.results:\n",
        "        annotation_recs = suggest_annotation_approach(\n",
        "            eda.results['spot_metrics'],\n",
        "            eda.results['class_counts']\n",
        "        )\n",
        "\n",
        "        # Save annotation recommendations\n",
        "        with open(os.path.join(\"/content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Output_v1\", \"annotation_recommendations.json\"), \"w\") as f:\n",
        "            json.dump(annotation_recs, f, indent=4)\n",
        "\n",
        "        print(\"\\nAnnotation recommendations generated and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NPPX0pRAQo-",
        "outputId": "5003ce82-db20-4b9c-f0ed-e3de411ad237"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full EDA on Groundnut Leaf Spot dataset at /content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Data/wetransfer_leafspot-scores-photos_2024-03-20_1533\n",
            "Results will be saved to /content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Output_v1\n",
            "Analyzing dataset structure...\n",
            "Total images: 273\n",
            "Leafspot Scale 1: 37 images (13.55%)\n",
            "Leafspot Scale 2: 40 images (14.65%)\n",
            "Leafspot Scale 3: 48 images (17.58%)\n",
            "Leafspot Scale 4: 27 images (9.89%)\n",
            "Leafspot Scale 5: 56 images (20.51%)\n",
            "Leafspot Scale 6: 65 images (23.81%)\n",
            "Analyzing image properties...\n",
            "Analyzing image quality...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0a7591832a40>:253: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=[c for c in class_brightness.keys() if class_brightness[c]])\n",
            "<ipython-input-3-0a7591832a40>:265: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=[c for c in class_contrast.keys() if class_contrast[c]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing color distributions...\n",
            "Sampling images from each class...\n",
            "Analyzing texture features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Leafspot Scale 1: 100%|██████████| 30/30 [00:11<00:00,  2.53it/s]\n",
            "Processing Leafspot Scale 2: 100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "Processing Leafspot Scale 3: 100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "Processing Leafspot Scale 4: 100%|██████████| 27/27 [00:11<00:00,  2.29it/s]\n",
            "Processing Leafspot Scale 5: 100%|██████████| 30/30 [00:07<00:00,  3.76it/s]\n",
            "Processing Leafspot Scale 6: 100%|██████████| 30/30 [00:10<00:00,  2.76it/s]\n",
            "<ipython-input-3-0a7591832a40>:614: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n",
            "<ipython-input-3-0a7591832a40>:614: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n",
            "<ipython-input-3-0a7591832a40>:614: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n",
            "<ipython-input-3-0a7591832a40>:614: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n",
            "<ipython-input-3-0a7591832a40>:614: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing leaf spot specific features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0a7591832a40>:856: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n",
            "<ipython-input-3-0a7591832a40>:876: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  plt.boxplot(data_to_plot, labels=labels)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting potential issues...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking images: 100%|██████████| 177/177 [01:29<00:00,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Potential issues detected:\n",
            "  duplicates: 0 images\n",
            "  corrupted: 0 images\n",
            "  very_low_brightness: 0 images\n",
            "  very_high_brightness: 0 images\n",
            "  very_blurry: 66 images\n",
            "  unusual_aspect_ratio: 0 images\n",
            "  outlier_size: 177 images\n",
            "\n",
            "========== EDA REPORT ==========\n",
            "Dataset contains 273 images across 6 classes\n",
            "\n",
            "Image Properties:\n",
            "  - 4 unique image dimensions\n",
            "  - Average file size: 6676.75 KB\n",
            "  - File formats: {'.jpg': 273}\n",
            "\n",
            "Image Quality:\n",
            "  - Average brightness: 116.49\n",
            "  - Average contrast: 52.86\n",
            "  - Average blur score: 210.99\n",
            "\n",
            "Issues Detected:\n",
            "  - duplicates: 0\n",
            "  - corrupted: 0\n",
            "  - very_low_brightness: 0\n",
            "  - very_high_brightness: 0\n",
            "  - very_blurry: 66\n",
            "  - unusual_aspect_ratio: 0\n",
            "  - outlier_size: 177\n",
            "\n",
            "Cleaning Recommendations:\n",
            "  1. Consider removing or enhancing 66 blurry images.\n",
            "  2. Address class imbalance through augmentation of minority classes or sampling strategies.\n",
            "\n",
            "EDA completed. Results saved to /content/drive/MyDrive/MSCS_folder/Computer-Vision/Assignment three/Output_v1\n",
            "\n",
            "Annotation recommendations generated and saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}